{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Main Changes of Original Model\n",
    "## Try Different Parameters in Each Model for Multiple Times (Detailed Outputs in the Excel Files - Post On BB)\n",
    "## 2 Add a XGBoost At the End of This File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DURATION:  0:00:02.906858\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Libraries to load\n",
    "# !pip install lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "print('LOAD DURATION: ', datetime.now() - start_time) # load time about 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 55.2 s, total: 3min 30s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vars_total = pd.read_csv('vars_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars.rename(columns={'fraud_label':'Fraud'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14393"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>ssn_age_level_count_0_by_30</th>\n",
       "      <th>ssn_age_level_count_0_by_14</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_count_30</th>\n",
       "      <th>...</th>\n",
       "      <th>ssn_age_level_count_14</th>\n",
       "      <th>ssn_name_dob_count_14</th>\n",
       "      <th>ssn_lastname_count_14</th>\n",
       "      <th>name_dob_count_0_by_30</th>\n",
       "      <th>ssn_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_0_by_14</th>\n",
       "      <th>ssn_lastname_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_7</th>\n",
       "      <th>ssn_name_count_0_by_14</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   record  fulladdress_count_30  ssn_firstname_count_30  homephone_count_3  \\\n",
       "0       1                     1                       1                  1   \n",
       "1       2                     1                       1                  1   \n",
       "2       3                     1                       1                  1   \n",
       "3       4                     1                       1                  1   \n",
       "4       5                     1                       1                  1   \n",
       "5       6                     1                       1                  1   \n",
       "6       7                     1                       1                  1   \n",
       "7       8                     1                       1                  1   \n",
       "8       9                     1                       1                  1   \n",
       "9      10                     1                       1                  1   \n",
       "\n",
       "   ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "0                 1                               1   \n",
       "1                 1                               1   \n",
       "2                 1                               1   \n",
       "3                 1                               1   \n",
       "4                 1                               1   \n",
       "5                 1                               1   \n",
       "6                 1                               1   \n",
       "7                 1                               1   \n",
       "8                 1                               1   \n",
       "9                 1                               1   \n",
       "\n",
       "   ssn_age_level_count_0_by_30  ssn_age_level_count_0_by_14  \\\n",
       "0                         30.0                         14.0   \n",
       "1                         30.0                         14.0   \n",
       "2                         30.0                         14.0   \n",
       "3                         30.0                         14.0   \n",
       "4                         30.0                         14.0   \n",
       "5                         30.0                         14.0   \n",
       "6                         30.0                         14.0   \n",
       "7                         30.0                         14.0   \n",
       "8                         30.0                         14.0   \n",
       "9                         30.0                         14.0   \n",
       "\n",
       "   name_dob_count_30  ssn_name_count_30  ...  ssn_age_level_count_14  \\\n",
       "0                  1                  1  ...                       1   \n",
       "1                  1                  1  ...                       1   \n",
       "2                  1                  1  ...                       1   \n",
       "3                  1                  1  ...                       1   \n",
       "4                  1                  1  ...                       1   \n",
       "5                  1                  1  ...                       1   \n",
       "6                  1                  1  ...                       1   \n",
       "7                  1                  1  ...                       1   \n",
       "8                  1                  1  ...                       1   \n",
       "9                  1                  1  ...                       1   \n",
       "\n",
       "   ssn_name_dob_count_14  ssn_lastname_count_14  name_dob_count_0_by_30  \\\n",
       "0                      1                      1                    30.0   \n",
       "1                      1                      1                    30.0   \n",
       "2                      1                      1                    30.0   \n",
       "3                      1                      1                    30.0   \n",
       "4                      1                      1                    30.0   \n",
       "5                      1                      1                    30.0   \n",
       "6                      1                      1                    30.0   \n",
       "7                      1                      1                    30.0   \n",
       "8                      1                      1                    30.0   \n",
       "9                      1                      1                    30.0   \n",
       "\n",
       "   ssn_count_0_by_14  ssn_name_dob_count_0_by_14  ssn_lastname_count_0_by_14  \\\n",
       "0               14.0                        14.0                        14.0   \n",
       "1               14.0                        14.0                        14.0   \n",
       "2               14.0                        14.0                        14.0   \n",
       "3               14.0                        14.0                        14.0   \n",
       "4               14.0                        14.0                        14.0   \n",
       "5               14.0                        14.0                        14.0   \n",
       "6               14.0                        14.0                        14.0   \n",
       "7               14.0                        14.0                        14.0   \n",
       "8               14.0                        14.0                        14.0   \n",
       "9               14.0                        14.0                        14.0   \n",
       "\n",
       "   ssn_name_dob_count_7  ssn_name_count_0_by_14  Fraud  \n",
       "0                     1                    14.0      0  \n",
       "1                     1                    14.0      1  \n",
       "2                     1                    14.0      0  \n",
       "3                     1                    14.0      0  \n",
       "4                     1                    14.0      0  \n",
       "5                     1                    14.0      0  \n",
       "6                     1                    14.0      0  \n",
       "7                     1                    14.0      0  \n",
       "8                     1                    14.0      0  \n",
       "9                     1                    14.0      0  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 27)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>ssn_age_level_count_0_by_30</th>\n",
       "      <th>ssn_age_level_count_0_by_14</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_count_30</th>\n",
       "      <th>...</th>\n",
       "      <th>ssn_age_level_count_14</th>\n",
       "      <th>ssn_name_dob_count_14</th>\n",
       "      <th>ssn_lastname_count_14</th>\n",
       "      <th>name_dob_count_0_by_30</th>\n",
       "      <th>ssn_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_0_by_14</th>\n",
       "      <th>ssn_lastname_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_7</th>\n",
       "      <th>ssn_name_count_0_by_14</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500000.500000</td>\n",
       "      <td>1.064624</td>\n",
       "      <td>1.048903</td>\n",
       "      <td>1.449296</td>\n",
       "      <td>1.046097</td>\n",
       "      <td>1.048207</td>\n",
       "      <td>29.545788</td>\n",
       "      <td>13.885564</td>\n",
       "      <td>1.046295</td>\n",
       "      <td>1.048778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033714</td>\n",
       "      <td>1.032193</td>\n",
       "      <td>1.033601</td>\n",
       "      <td>29.584207</td>\n",
       "      <td>13.882687</td>\n",
       "      <td>13.895295</td>\n",
       "      <td>13.885818</td>\n",
       "      <td>1.025098</td>\n",
       "      <td>13.886118</td>\n",
       "      <td>0.014393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288675.278933</td>\n",
       "      <td>0.633831</td>\n",
       "      <td>0.499029</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.496315</td>\n",
       "      <td>0.507682</td>\n",
       "      <td>2.653148</td>\n",
       "      <td>0.926658</td>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.498892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473324</td>\n",
       "      <td>0.471479</td>\n",
       "      <td>0.472915</td>\n",
       "      <td>2.546141</td>\n",
       "      <td>0.940186</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.924867</td>\n",
       "      <td>0.451121</td>\n",
       "      <td>0.923737</td>\n",
       "      <td>0.119104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250000.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500000.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750000.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               record  fulladdress_count_30  ssn_firstname_count_30  \\\n",
       "count  1000000.000000        1000000.000000          1000000.000000   \n",
       "mean    500000.500000              1.064624                1.048903   \n",
       "std     288675.278933              0.633831                0.499029   \n",
       "min          1.000000              1.000000                1.000000   \n",
       "25%     250000.750000              1.000000                1.000000   \n",
       "50%     500000.500000              1.000000                1.000000   \n",
       "75%     750000.250000              1.000000                1.000000   \n",
       "max    1000000.000000             30.000000               34.000000   \n",
       "\n",
       "       homephone_count_3  ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "count     1000000.000000    1000000.000000                  1000000.000000   \n",
       "mean            1.449296          1.046097                        1.048207   \n",
       "std             0.861622          0.496315                        0.507682   \n",
       "min             1.000000          1.000000                        1.000000   \n",
       "25%             1.000000          1.000000                        1.000000   \n",
       "50%             1.000000          1.000000                        1.000000   \n",
       "75%             2.000000          1.000000                        1.000000   \n",
       "max            32.000000         34.000000                       30.000000   \n",
       "\n",
       "       ssn_age_level_count_0_by_30  ssn_age_level_count_0_by_14  \\\n",
       "count               1000000.000000               1000000.000000   \n",
       "mean                     29.545788                    13.885564   \n",
       "std                       2.653148                     0.926658   \n",
       "min                       1.363636                     0.636364   \n",
       "25%                      30.000000                    14.000000   \n",
       "50%                      30.000000                    14.000000   \n",
       "75%                      30.000000                    14.000000   \n",
       "max                      30.000000                    14.000000   \n",
       "\n",
       "       name_dob_count_30  ssn_name_count_30  ...  ssn_age_level_count_14  \\\n",
       "count     1000000.000000     1000000.000000  ...          1000000.000000   \n",
       "mean            1.046295           1.048778  ...                1.033714   \n",
       "std             0.496914           0.498892  ...                0.473324   \n",
       "min             1.000000           1.000000  ...                1.000000   \n",
       "25%             1.000000           1.000000  ...                1.000000   \n",
       "50%             1.000000           1.000000  ...                1.000000   \n",
       "75%             1.000000           1.000000  ...                1.000000   \n",
       "max            34.000000          34.000000  ...               34.000000   \n",
       "\n",
       "       ssn_name_dob_count_14  ssn_lastname_count_14  name_dob_count_0_by_30  \\\n",
       "count         1000000.000000         1000000.000000          1000000.000000   \n",
       "mean                1.032193               1.033601               29.584207   \n",
       "std                 0.471479               0.472915                2.546141   \n",
       "min                 1.000000               1.000000                1.363636   \n",
       "25%                 1.000000               1.000000               30.000000   \n",
       "50%                 1.000000               1.000000               30.000000   \n",
       "75%                 1.000000               1.000000               30.000000   \n",
       "max                34.000000              34.000000               30.000000   \n",
       "\n",
       "       ssn_count_0_by_14  ssn_name_dob_count_0_by_14  \\\n",
       "count     1000000.000000              1000000.000000   \n",
       "mean           13.882687                   13.895295   \n",
       "std             0.940186                    0.889286   \n",
       "min             0.636364                    0.636364   \n",
       "25%            14.000000                   14.000000   \n",
       "50%            14.000000                   14.000000   \n",
       "75%            14.000000                   14.000000   \n",
       "max            14.000000                   14.000000   \n",
       "\n",
       "       ssn_lastname_count_0_by_14  ssn_name_dob_count_7  \\\n",
       "count              1000000.000000        1000000.000000   \n",
       "mean                    13.885818              1.025098   \n",
       "std                      0.924867              0.451121   \n",
       "min                      0.636364              1.000000   \n",
       "25%                     14.000000              1.000000   \n",
       "50%                     14.000000              1.000000   \n",
       "75%                     14.000000              1.000000   \n",
       "max                     14.000000             34.000000   \n",
       "\n",
       "       ssn_name_count_0_by_14           Fraud  \n",
       "count          1000000.000000  1000000.000000  \n",
       "mean                13.886118        0.014393  \n",
       "std                  0.923737        0.119104  \n",
       "min                  0.636364        0.000000  \n",
       "25%                 14.000000        0.000000  \n",
       "50%                 14.000000        0.000000  \n",
       "75%                 14.000000        0.000000  \n",
       "max                 14.000000        1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['record']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>ssn_age_level_count_0_by_30</th>\n",
       "      <th>ssn_age_level_count_0_by_14</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_count_30</th>\n",
       "      <th>ssn_dob_count_14</th>\n",
       "      <th>...</th>\n",
       "      <th>name_dob_count_14</th>\n",
       "      <th>ssn_age_level_count_14</th>\n",
       "      <th>ssn_name_dob_count_14</th>\n",
       "      <th>ssn_lastname_count_14</th>\n",
       "      <th>name_dob_count_0_by_30</th>\n",
       "      <th>ssn_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_0_by_14</th>\n",
       "      <th>ssn_lastname_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_7</th>\n",
       "      <th>ssn_name_count_0_by_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.064624</td>\n",
       "      <td>1.048903</td>\n",
       "      <td>1.449296</td>\n",
       "      <td>1.046097</td>\n",
       "      <td>1.048207</td>\n",
       "      <td>29.545788</td>\n",
       "      <td>13.885564</td>\n",
       "      <td>1.046295</td>\n",
       "      <td>1.048778</td>\n",
       "      <td>1.03226</td>\n",
       "      <td>...</td>\n",
       "      <td>1.032363</td>\n",
       "      <td>1.033714</td>\n",
       "      <td>1.032193</td>\n",
       "      <td>1.033601</td>\n",
       "      <td>29.584207</td>\n",
       "      <td>13.882687</td>\n",
       "      <td>13.895295</td>\n",
       "      <td>13.885818</td>\n",
       "      <td>1.025098</td>\n",
       "      <td>13.886118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.633831</td>\n",
       "      <td>0.499029</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.496315</td>\n",
       "      <td>0.507682</td>\n",
       "      <td>2.653148</td>\n",
       "      <td>0.926658</td>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.498892</td>\n",
       "      <td>0.47155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471763</td>\n",
       "      <td>0.473324</td>\n",
       "      <td>0.471479</td>\n",
       "      <td>0.472915</td>\n",
       "      <td>2.546141</td>\n",
       "      <td>0.940186</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.924867</td>\n",
       "      <td>0.451121</td>\n",
       "      <td>0.923737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fulladdress_count_30  ssn_firstname_count_30  homephone_count_3  \\\n",
       "count        1000000.000000          1000000.000000     1000000.000000   \n",
       "mean               1.064624                1.048903           1.449296   \n",
       "std                0.633831                0.499029           0.861622   \n",
       "min                1.000000                1.000000           1.000000   \n",
       "25%                1.000000                1.000000           1.000000   \n",
       "50%                1.000000                1.000000           1.000000   \n",
       "75%                1.000000                1.000000           2.000000   \n",
       "max               30.000000               34.000000          32.000000   \n",
       "\n",
       "       ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "count    1000000.000000                  1000000.000000   \n",
       "mean           1.046097                        1.048207   \n",
       "std            0.496315                        0.507682   \n",
       "min            1.000000                        1.000000   \n",
       "25%            1.000000                        1.000000   \n",
       "50%            1.000000                        1.000000   \n",
       "75%            1.000000                        1.000000   \n",
       "max           34.000000                       30.000000   \n",
       "\n",
       "       ssn_age_level_count_0_by_30  ssn_age_level_count_0_by_14  \\\n",
       "count               1000000.000000               1000000.000000   \n",
       "mean                     29.545788                    13.885564   \n",
       "std                       2.653148                     0.926658   \n",
       "min                       1.363636                     0.636364   \n",
       "25%                      30.000000                    14.000000   \n",
       "50%                      30.000000                    14.000000   \n",
       "75%                      30.000000                    14.000000   \n",
       "max                      30.000000                    14.000000   \n",
       "\n",
       "       name_dob_count_30  ssn_name_count_30  ssn_dob_count_14  ...  \\\n",
       "count     1000000.000000     1000000.000000     1000000.00000  ...   \n",
       "mean            1.046295           1.048778           1.03226  ...   \n",
       "std             0.496914           0.498892           0.47155  ...   \n",
       "min             1.000000           1.000000           1.00000  ...   \n",
       "25%             1.000000           1.000000           1.00000  ...   \n",
       "50%             1.000000           1.000000           1.00000  ...   \n",
       "75%             1.000000           1.000000           1.00000  ...   \n",
       "max            34.000000          34.000000          34.00000  ...   \n",
       "\n",
       "       name_dob_count_14  ssn_age_level_count_14  ssn_name_dob_count_14  \\\n",
       "count     1000000.000000          1000000.000000         1000000.000000   \n",
       "mean            1.032363                1.033714               1.032193   \n",
       "std             0.471763                0.473324               0.471479   \n",
       "min             1.000000                1.000000               1.000000   \n",
       "25%             1.000000                1.000000               1.000000   \n",
       "50%             1.000000                1.000000               1.000000   \n",
       "75%             1.000000                1.000000               1.000000   \n",
       "max            34.000000               34.000000              34.000000   \n",
       "\n",
       "       ssn_lastname_count_14  name_dob_count_0_by_30  ssn_count_0_by_14  \\\n",
       "count         1000000.000000          1000000.000000     1000000.000000   \n",
       "mean                1.033601               29.584207          13.882687   \n",
       "std                 0.472915                2.546141           0.940186   \n",
       "min                 1.000000                1.363636           0.636364   \n",
       "25%                 1.000000               30.000000          14.000000   \n",
       "50%                 1.000000               30.000000          14.000000   \n",
       "75%                 1.000000               30.000000          14.000000   \n",
       "max                34.000000               30.000000          14.000000   \n",
       "\n",
       "       ssn_name_dob_count_0_by_14  ssn_lastname_count_0_by_14  \\\n",
       "count              1000000.000000              1000000.000000   \n",
       "mean                    13.895295                   13.885818   \n",
       "std                      0.889286                    0.924867   \n",
       "min                      0.636364                    0.636364   \n",
       "25%                     14.000000                   14.000000   \n",
       "50%                     14.000000                   14.000000   \n",
       "75%                     14.000000                   14.000000   \n",
       "max                     14.000000                   14.000000   \n",
       "\n",
       "       ssn_name_dob_count_7  ssn_name_count_0_by_14  \n",
       "count        1000000.000000          1000000.000000  \n",
       "mean               1.025098               13.886118  \n",
       "std                0.451121                0.923737  \n",
       "min                1.000000                0.636364  \n",
       "25%                1.000000               14.000000  \n",
       "50%                1.000000               14.000000  \n",
       "75%                1.000000               14.000000  \n",
       "max               34.000000               14.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['record','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>ssn_age_level_count_0_by_30</th>\n",
       "      <th>ssn_age_level_count_0_by_14</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_count_30</th>\n",
       "      <th>ssn_dob_count_14</th>\n",
       "      <th>...</th>\n",
       "      <th>name_dob_count_14</th>\n",
       "      <th>ssn_age_level_count_14</th>\n",
       "      <th>ssn_name_dob_count_14</th>\n",
       "      <th>ssn_lastname_count_14</th>\n",
       "      <th>name_dob_count_0_by_30</th>\n",
       "      <th>ssn_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_0_by_14</th>\n",
       "      <th>ssn_lastname_count_0_by_14</th>\n",
       "      <th>ssn_name_dob_count_7</th>\n",
       "      <th>ssn_name_count_0_by_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.018176</td>\n",
       "      <td>-0.017457</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>-0.017649</td>\n",
       "      <td>-0.018020</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>-0.017617</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>-0.018502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018486</td>\n",
       "      <td>-0.018362</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>-0.018393</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>-0.018700</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.631721</td>\n",
       "      <td>0.579481</td>\n",
       "      <td>0.910935</td>\n",
       "      <td>0.571302</td>\n",
       "      <td>0.576299</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.970439</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>0.579076</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519888</td>\n",
       "      <td>0.525781</td>\n",
       "      <td>0.518828</td>\n",
       "      <td>0.524293</td>\n",
       "      <td>0.998362</td>\n",
       "      <td>0.970586</td>\n",
       "      <td>0.961009</td>\n",
       "      <td>0.970455</td>\n",
       "      <td>0.483844</td>\n",
       "      <td>0.970243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>-0.521454</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-0.068413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>-0.071228</td>\n",
       "      <td>-0.068281</td>\n",
       "      <td>-0.071051</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-0.055635</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>-0.521454</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.123493</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-0.068413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>-0.071228</td>\n",
       "      <td>-0.068281</td>\n",
       "      <td>-0.071051</td>\n",
       "      <td>0.163303</td>\n",
       "      <td>0.124777</td>\n",
       "      <td>0.117741</td>\n",
       "      <td>0.123458</td>\n",
       "      <td>-0.055635</td>\n",
       "      <td>0.123284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>-0.521454</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.123493</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-0.068413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>-0.071228</td>\n",
       "      <td>-0.068281</td>\n",
       "      <td>-0.071051</td>\n",
       "      <td>0.163303</td>\n",
       "      <td>0.124777</td>\n",
       "      <td>0.117741</td>\n",
       "      <td>0.123458</td>\n",
       "      <td>-0.055635</td>\n",
       "      <td>0.123284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>0.639148</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.123493</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-0.068413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>-0.071228</td>\n",
       "      <td>-0.068281</td>\n",
       "      <td>-0.071051</td>\n",
       "      <td>0.163303</td>\n",
       "      <td>0.124777</td>\n",
       "      <td>0.117741</td>\n",
       "      <td>0.123458</td>\n",
       "      <td>-0.055635</td>\n",
       "      <td>0.123284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.123493</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.163303</td>\n",
       "      <td>0.124777</td>\n",
       "      <td>0.117741</td>\n",
       "      <td>0.123458</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.123284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fulladdress_count_30  ssn_firstname_count_30  homephone_count_3  \\\n",
       "count        1000000.000000          1000000.000000     1000000.000000   \n",
       "mean              -0.018176               -0.017457          -0.005814   \n",
       "std                0.631721                0.579481           0.910935   \n",
       "min               -0.101958               -0.097996          -0.521454   \n",
       "25%               -0.101958               -0.097996          -0.521454   \n",
       "50%               -0.101958               -0.097996          -0.521454   \n",
       "75%               -0.101958               -0.097996           0.639148   \n",
       "max               10.000000               10.000000          10.000000   \n",
       "\n",
       "       ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "count    1000000.000000                  1000000.000000   \n",
       "mean          -0.017649                       -0.018020   \n",
       "std            0.571302                        0.576299   \n",
       "min           -0.092879                       -0.094955   \n",
       "25%           -0.092879                       -0.094955   \n",
       "50%           -0.092879                       -0.094955   \n",
       "75%           -0.092879                       -0.094955   \n",
       "max           10.000000                       10.000000   \n",
       "\n",
       "       ssn_age_level_count_0_by_30  ssn_age_level_count_0_by_14  \\\n",
       "count               1000000.000000               1000000.000000   \n",
       "mean                      0.000035                     0.002577   \n",
       "std                       0.999643                     0.970439   \n",
       "min                     -10.000000                   -10.000000   \n",
       "25%                       0.171197                     0.123493   \n",
       "50%                       0.171197                     0.123493   \n",
       "75%                       0.171197                     0.123493   \n",
       "max                       0.171197                     0.123493   \n",
       "\n",
       "       name_dob_count_30  ssn_name_count_30  ssn_dob_count_14  ...  \\\n",
       "count     1000000.000000     1000000.000000    1000000.000000  ...   \n",
       "mean           -0.017617          -0.017467         -0.018502  ...   \n",
       "std             0.572884           0.579076          0.519100  ...   \n",
       "min            -0.093165          -0.097773         -0.068413  ...   \n",
       "25%            -0.093165          -0.097773         -0.068413  ...   \n",
       "50%            -0.093165          -0.097773         -0.068413  ...   \n",
       "75%            -0.093165          -0.097773         -0.068413  ...   \n",
       "max            10.000000          10.000000         10.000000  ...   \n",
       "\n",
       "       name_dob_count_14  ssn_age_level_count_14  ssn_name_dob_count_14  \\\n",
       "count     1000000.000000          1000000.000000         1000000.000000   \n",
       "mean           -0.018486               -0.018362              -0.018507   \n",
       "std             0.519888                0.525781               0.518828   \n",
       "min            -0.068600               -0.071228              -0.068281   \n",
       "25%            -0.068600               -0.071228              -0.068281   \n",
       "50%            -0.068600               -0.071228              -0.068281   \n",
       "75%            -0.068600               -0.071228              -0.068281   \n",
       "max            10.000000               10.000000              10.000000   \n",
       "\n",
       "       ssn_lastname_count_14  name_dob_count_0_by_30  ssn_count_0_by_14  \\\n",
       "count         1000000.000000          1000000.000000     1000000.000000   \n",
       "mean               -0.018393                0.000159           0.002583   \n",
       "std                 0.524293                0.998362           0.970586   \n",
       "min                -0.071051              -10.000000         -10.000000   \n",
       "25%                -0.071051                0.163303           0.124777   \n",
       "50%                -0.071051                0.163303           0.124777   \n",
       "75%                -0.071051                0.163303           0.124777   \n",
       "max                10.000000                0.163303           0.124777   \n",
       "\n",
       "       ssn_name_dob_count_0_by_14  ssn_lastname_count_0_by_14  \\\n",
       "count              1000000.000000              1000000.000000   \n",
       "mean                     0.003333                    0.002572   \n",
       "std                      0.961009                    0.970455   \n",
       "min                    -10.000000                  -10.000000   \n",
       "25%                      0.117741                    0.123458   \n",
       "50%                      0.117741                    0.123458   \n",
       "75%                      0.117741                    0.123458   \n",
       "max                      0.117741                    0.123458   \n",
       "\n",
       "       ssn_name_dob_count_7  ssn_name_count_0_by_14  \n",
       "count        1000000.000000          1000000.000000  \n",
       "mean              -0.018700                0.002588  \n",
       "std                0.483844                0.970243  \n",
       "min               -0.055635              -10.000000  \n",
       "25%               -0.055635                0.123284  \n",
       "50%               -0.055635                0.123284  \n",
       "75%               -0.055635                0.123284  \n",
       "max               10.000000                0.123284  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values\n",
    "cols = X.columns\n",
    "X.loc[:,cols] = X[cols].clip(upper=Clip)\n",
    "X.loc[:,cols] = X[cols].clip(lower=-1*Clip)\n",
    "# X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time\n",
    "X_trntst = X[0:833507]\n",
    "Y_trntst = Y_save[0:833507]\n",
    "X_oot = X[833507:]\n",
    "Y_oot = Y_save[833507:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 0\n",
    "nitermax = 3\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL THE CODES ABOVE THIS CELL SHOULD BE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "CPU times: user 12min 14s, sys: 5.21 s, total: 12min 19s\n",
      "Wall time: 9min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "log = pd.DataFrame(columns=['num_vars','penalty','solver','c','train','test','oot'])\n",
    "number_var = []\n",
    "penalty_num = []\n",
    "solver_type = []\n",
    "c_value = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [i for i in range(6,21) if i%2==0]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for penalty in ['l1','l2']:\n",
    "        for solver in ['lbfgs','saga']:\n",
    "            for c in [0.1,0.3,0.6,1,3]:\n",
    "                try:\n",
    "                    for niter in range(nitermax):    \n",
    "                        X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                        model = LogisticRegression(penalty=penalty,solver=solver,C=c)\n",
    "\n",
    "                        X_oot = X_oot_orig.copy()\n",
    "                        X_trn_save = X_trn.copy()\n",
    "                        Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                        model.fit(X_trn, Y_trn.values.ravel())   \n",
    "                        predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                        X_trn['predicted'] = predictions\n",
    "                        X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                        topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                        temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_tst)[:,1]\n",
    "                        X_tst['predicted']=predictions\n",
    "                        X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                        topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                        temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                        X_oot['predicted']=predictions\n",
    "                        X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                        topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                        temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                    number_var.append(num_vars)\n",
    "                    penalty_num.append(penalty)\n",
    "                    solver_type.append(solver)\n",
    "                    c_value.append(c)\n",
    "                    train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                    test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                    oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                    print(\"finished!\")\n",
    "                except:\n",
    "                    print('bad_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = pd.DataFrame(data={'num_vars':number_var,'penalty':penalty_num,'solver':solver_type,'c':c_value,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm.to_excel(\"ligstic_MultipleVarsTrial.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models. You can comment out any of these cells and just explore one model type. You can also just rerun that single cell multiple times as you explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 1min 57s, sys: 16.8 s, total: 2min 14s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "number_var = []\n",
    "criterion_type = []\n",
    "splitter_type = []\n",
    "max_depth_num= []\n",
    "min_samples_leaf_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [i for i in range(6,21) if i%2==0]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for criterion in ['gini','entropy']:\n",
    "        for splitter in ['best']:\n",
    "            for max_depth in [5,10,15,20]:\n",
    "                for min_samples_leaf in [15,20,25,30,40]:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = DecisionTreeClassifier(criterion=criterion,splitter=splitter,max_depth=max_depth,min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                        number_var.append(num_vars)\n",
    "                        criterion_type.append(criterion)\n",
    "                        splitter_type.append(splitter)\n",
    "                        max_depth_num.append(max_depth)\n",
    "                        min_samples_leaf_num.append(min_samples_leaf)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame(data={'num_vars':number_var,'criterion':criterion_type,'splitter':splitter_type,'max_depth':max_depth_num,'min_samples_leaf':min_samples_leaf_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_excel(\"decision_MultipleVarsTrial.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 1h 29min 16s, sys: 3min 8s, total: 1h 32min 25s\n",
      "Wall time: 1h 32min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "number_var = []\n",
    "criterion_type = []\n",
    "n_estimators_num = []\n",
    "max_depth_num= []\n",
    "max_features_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [20,25]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for n_estimators in [10,50,100,150]:\n",
    "        for max_depth in [10,20,30]:\n",
    "            for cirterion in ['gini','entropy']:\n",
    "                for max_features in [\"auto\",\"log2\"]:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,criterion=criterion,max_features=max_features)\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                            \n",
    "                        number_var.append(num_vars)\n",
    "                        criterion_type.append(criterion)\n",
    "                        n_estimators_num.append(n_estimators)\n",
    "                        max_depth_num.append(max_depth)\n",
    "                        max_features_num.append(max_features)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.DataFrame(data={'num_vars':number_var,'criterion':criterion_type,'n_estimators':n_estimators_num,'max_depth':max_depth_num,'max_features':max_features_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.to_excel('rf.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 18h 30min 36s, sys: 17min 34s, total: 18h 48min 10s\n",
      "Wall time: 3h 29min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BT\n",
    "number_var = []\n",
    "learning_rate_num = []\n",
    "n_estimators_num = []\n",
    "max_depth_num= []\n",
    "subsample_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [15,20]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for n_estimators in [100,200,500,1000]:\n",
    "        for max_depth in [3,4,5]:\n",
    "            for learning_rate in [0.001,0.01,0.02,0.05,0.1]:\n",
    "                for subsample in [0.7,0.8,1]:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = lgb.LGBMClassifier(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate,subsample=subsample)\n",
    "\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                            \n",
    "                        number_var.append(num_vars)\n",
    "                        learning_rate_num.append(learning_rate)\n",
    "                        n_estimators_num.append(n_estimators)\n",
    "                        max_depth_num.append(max_depth)\n",
    "                        subsample_num.append(subsample)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = pd.DataFrame(data={'num_vars':number_var,'learning_rate':learning_rate_num,'n_estimators':n_estimators_num,'max_depth':max_depth_num,'subsample':subsample_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.to_excel(\"bt.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 22min 24s, sys: 11.8 s, total: 22min 36s\n",
      "Wall time: 19min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN\n",
    "number_var = []\n",
    "hidden_layer_size_num = []\n",
    "max_iter_num = []\n",
    "learning_rate_type = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [6,8,12,16]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for hidden_layer_sizes in [20,(20,10),(10,5)]:\n",
    "        for max_iter in [20,40,60,100]:\n",
    "            for learning_rate in ['invscaling','constant']:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,max_iter=max_iter,learning_rate=learning_rate)\n",
    "\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                            \n",
    "                        number_var.append(num_vars)\n",
    "                        hidden_layer_size_num.append(hidden_layer_sizes)\n",
    "                        max_iter_num.append(max_iter)\n",
    "                        learning_rate_type.append(learning_rate)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = pd.DataFrame(data={'num_vars':number_var,'hidden_layer_size':hidden_layer_size_num,'max_iter':max_iter_num,'learning_rate':learning_rate_type,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.to_excel(\"nn_MultipleVarsTrial.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:40:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:41:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:41:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:42:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:42:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:42:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:43:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:45:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:46:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:46:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:47:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:47:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:48:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:48:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:49:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:49:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:49:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:50:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "[12:50:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:51:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:51:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:51:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:52:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:52:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:52:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:53:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:53:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:53:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:54:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:54:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:54:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:54:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:55:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:55:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:55:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:56:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:56:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:56:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:57:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:57:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:58:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:58:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[12:59:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[13:00:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[13:00:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "[13:00:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[13:01:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "CPU times: user 4h 8min 53s, sys: 1min 4s, total: 4h 9min 57s\n",
      "Wall time: 21min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "number_var = []\n",
    "learning_rate_num = []\n",
    "n_estimators_num = []\n",
    "max_depth_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [8,10,12,16]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for n_estimators in [100,200,500,800,1000]:\n",
    "        for learning_rate in [0.05,0.1,0.3,0.5]:\n",
    "            for max_depth in [3,4,5]:\n",
    "                try:\n",
    "                    for niter in range(nitermax):    \n",
    "                        X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                        model = XGBClassifier(seed=47)\n",
    "\n",
    "                        X_oot = X_oot_orig.copy()\n",
    "                        X_trn_save = X_trn.copy()\n",
    "                        Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                        model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                        predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                        X_trn['predicted'] = predictions\n",
    "                        X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                        topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                        temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_tst)[:,1]\n",
    "                        X_tst['predicted']=predictions\n",
    "                        X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                        topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                        temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                        X_oot['predicted']=predictions\n",
    "                        X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                        topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                        temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "\n",
    "                    number_var.append(num_vars)\n",
    "                    learning_rate_num.append(learning_rate)\n",
    "                    n_estimators_num.append(n_estimators)\n",
    "                    max_depth_num.append(max_depth)\n",
    "                    train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                    test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                    oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                    print(\"finished!\")\n",
    "                except:\n",
    "                    print(\"bad model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = pd.DataFrame(data={'num_vars':number_var,'n_estimators':n_estimators_num,'learning_rate':learning_rate_num,'max_depth':max_depth_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.to_excel('xgboost_MultipleVarsTrial.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:03:48.900114\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
